{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import easydict\n",
    "from multiprocessing import Process\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "import torch\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "# torch\n",
    "import torchvision\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "from torchvision.models import mobilenet_v2\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision import transforms\n",
    "\n",
    "# from yolov5.train_dt import yolov5\n",
    "from EfficientObjectDetection.train_new_reward import EfficientOD\n",
    "\n",
    "# import fr_utils\n",
    "import munch\n",
    "import os\n",
    "import utils\n",
    "from utils import load_filenames, load_dataset, load_dataloader, compute_map, convert_yolo2coco, label2idx, label_matching, reduce_dict, make_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "opt = {'epochs':100,\n",
    "      'batch_size':12,\n",
    "      'device':1,\n",
    "      'test_epoch':10,\n",
    "      'eval_epoch':2,\n",
    "      'step_batch_size':100,\n",
    "      'save_path':'save',\n",
    "       'save_freq': 5,\n",
    "      'rl_weight':None,\n",
    "      'print_freq': 50,\n",
    "      'h_detector_weight':'',\n",
    "      'l_detector_weight':'',\n",
    "      'fine_tr':'config/fine_tr.yaml',\n",
    "      'fine_eval':'config/fine_eval.yaml',\n",
    "      'coarse_tr':'config/coarse_tr.yaml',\n",
    "      'coarse_eval':'config/coarse_eval.yaml',\n",
    "      'EfficientOD':'config/EfficientOD.yaml',\n",
    "      'split': 4}\n",
    "       \n",
    "opt = munch.AutoMunch(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU device  True\n"
     ]
    }
   ],
   "source": [
    "# GPU Device\n",
    "gpu_id = opt.device\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"GPU device \" , use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU device for EfficientOD:  True\n"
     ]
    }
   ],
   "source": [
    "# training option load from yaml files\n",
    "with open(opt.fine_tr) as f:\n",
    "    fine_tr = yaml.load(f, Loader=yaml.FullLoader)\n",
    "with open(opt.fine_eval) as f:\n",
    "    fine_eval = yaml.load(f, Loader=yaml.FullLoader)\n",
    "with open(opt.coarse_tr) as f:\n",
    "    coarse_tr = yaml.load(f, Loader=yaml.FullLoader)\n",
    "with open(opt.coarse_eval) as f:\n",
    "    coarse_eval = yaml.load(f, Loader=yaml.FullLoader)\n",
    "with open(opt.EfficientOD) as f:\n",
    "    efficient_config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "efficient_config['load'] = None # bug fix\n",
    "\n",
    "epochs = opt.epochs\n",
    "bs = opt.batch_size\n",
    "# fine_detector = yolov5(fine_tr, fine_eval, epochs, bs)\n",
    "# coarse_detector = yolov5(coarse_tr, coarse_eval, epochs, bs)\n",
    "rl_agent = EfficientOD(efficient_config)\n",
    "\n",
    "split_train_path = '/home/SSDD/ICIP21_dataset/800_HRSID/split_data_4_0/rl_ver/train/images'\n",
    "split_val_path = '/home/SSDD/ICIP21_dataset/800_HRSID/split_data_4_0/rl_ver/val/images'\n",
    "split_test_path = '/home/SSDD/ICIP21_dataset/800_HRSID/split_data_4_0/rl_ver/test/images'\n",
    "split = 4\n",
    "\n",
    "original_img_path = '/home/SSDD/ICIP21_dataset/800_HRSID/origin_data/rl_ver/'\n",
    "original_img_path_train = original_img_path + 'train/images'\n",
    "original_img_path_val = original_img_path + 'val/images'\n",
    "original_img_path_test = original_img_path + 'test/images'\n",
    "\n",
    "assert bs % split == 0, 'batch size should be divided with image split patch size'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FasterRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d()\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d()\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d()\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d()\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign()\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 2\n",
    "# anchor_generator = AnchorGenerator(sizes=((8,), (16,), (32,), (64,), (128,)), aspect_ratios=((0.5, 1.0, 2.0),(0.5, 1.0, 2.0),(0.5, 1.0, 2.0),(0.5, 1.0, 2.0),(0.5, 1.0, 2.0),))\n",
    "# fine_backbone = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=False, num_classes=1, pretrained_backbone=False).backbone\n",
    "# coarse_backbone = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=False, num_classes=1, pretrained_backbone=False).backbone\n",
    "\n",
    "# # roi\n",
    "# roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
    "\n",
    "# fine_model = FasterRCNN(fine_backbone, num_classes=num_classes, rpn_anchor_generator=anchor_generator, box_roi_pool=roi_pooler,\n",
    "#                        min_size=800, max_size=1333, rpn_nms_thresh=0.5, rpn_fg_iou_thresh=0.5)\n",
    "# coarse_model = FasterRCNN(coarse_backbone, num_classes=num_classes, rpn_anchor_generator=anchor_generator, box_roi_pool=roi_pooler,\n",
    "#                          min_size=800, max_size=1333, rpn_nms_thresh=0.5, rpn_fg_iou_thresh=0.5)\n",
    "\n",
    "fine_model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=False, num_classes=num_classes, pretrained_backbone=False)\n",
    "coarse_model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=False, num_classes=num_classes, pretrained_backbone=False)\n",
    "\n",
    "# # # # replace the classifier with a new one, that has\n",
    "# # # # num_classes which is user-defined\n",
    "\n",
    "# # # get number of input features for the classifier\n",
    "fine_in_features = fine_model.roi_heads.box_predictor.cls_score.in_features\n",
    "coarse_in_features = coarse_model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "# # # replace the pre-trained head with a new one\n",
    "fine_model.roi_heads.box_predictor = FastRCNNPredictor(fine_in_features, num_classes)\n",
    "coarse_model.roi_heads.box_predictor = FastRCNNPredictor(coarse_in_features, num_classes)\n",
    "\n",
    "for fine_p, coarse_p in zip(fine_model.parameters(), coarse_model.parameters()):\n",
    "    fine_p.requires_grad = True\n",
    "    coarse_p.requires_grad = True\n",
    "\n",
    "fine_model.to(device)\n",
    "coarse_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "fine_params = [p for p in fine_model.parameters() if p.requires_grad]\n",
    "coarse_params = [p for p in coarse_model.parameters() if p.requires_grad]\n",
    "\n",
    "fine_optim = torch.optim.SGD(fine_params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "coarse_optim = torch.optim.SGD(coarse_params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "fine_lr_scheduler = torch.optim.lr_scheduler.StepLR(fine_optim, step_size=50)\n",
    "coarse_lr_scheduler = torch.optim.lr_scheduler.StepLR(coarse_optim, step_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning labels /home/SSDD/ICIP21_dataset/800_HRSID/split_data_4_0/rl_ver/train/labels.cache (5299 found, 0 missing, 6353 empty, 0 duplicate, for 11652 images): 100%|██████████| 11652/11652 [00:00<00:00, 33203.21it/s]\n",
      "Scanning labels /home/SSDD/ICIP21_dataset/800_HRSID/split_data_4_0/rl_ver/train/labels.cache (5299 found, 0 missing, 6353 empty, 0 duplicate, for 11652 images): 100%|██████████| 11652/11652 [00:00<00:00, 34223.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine Epoch: [0]  [  0/971]  lr: 0.000010  loss: 2.9817 (2.9817)  loss_classifier: 1.8508 (1.8508)  loss_box_reg: 0.0123 (0.0123)  loss_objectness: 1.0221 (1.0221)  loss_rpn_box_reg: 0.0964 (0.0964)\n",
      "Coarse Epoch: [0]  [  0/971]  lr: 0.000010  loss: 1.0931 (1.0931)  loss_classifier: 0.5395 (0.5395)  loss_box_reg: 0.0083 (0.0083)  loss_objectness: 0.5086 (0.5086)  loss_rpn_box_reg: 0.0367 (0.0367)\n",
      "Fine Epoch: [0]  [ 50/971]  lr: 0.000268  loss: 0.2044 (0.5231)  loss_classifier: 0.0394 (0.1513)  loss_box_reg: 0.0015 (0.0124)  loss_objectness: 0.1289 (0.2533)  loss_rpn_box_reg: 0.0240 (0.1060)\n",
      "Coarse Epoch: [0]  [ 50/971]  lr: 0.000268  loss: 0.2147 (0.4303)  loss_classifier: 0.0286 (0.0899)  loss_box_reg: 0.0051 (0.0132)  loss_objectness: 0.1231 (0.2246)  loss_rpn_box_reg: 0.0289 (0.1026)\n",
      "Fine Epoch: [0]  [100/971]  lr: 0.000525  loss: 0.2370 (0.4211)  loss_classifier: 0.0535 (0.1034)  loss_box_reg: 0.0098 (0.0108)  loss_objectness: 0.1256 (0.2172)  loss_rpn_box_reg: 0.0327 (0.0897)\n",
      "Coarse Epoch: [0]  [100/971]  lr: 0.000525  loss: 0.2327 (0.3571)  loss_classifier: 0.0424 (0.0665)  loss_box_reg: 0.0046 (0.0109)  loss_objectness: 0.1437 (0.1971)  loss_rpn_box_reg: 0.0308 (0.0826)\n",
      "Fine Epoch: [0]  [150/971]  lr: 0.000783  loss: 0.1789 (0.3584)  loss_classifier: 0.0454 (0.0857)  loss_box_reg: 0.0158 (0.0129)  loss_objectness: 0.0978 (0.1879)  loss_rpn_box_reg: 0.0187 (0.0719)\n",
      "Coarse Epoch: [0]  [150/971]  lr: 0.000783  loss: 0.1726 (0.3145)  loss_classifier: 0.0403 (0.0607)  loss_box_reg: 0.0147 (0.0141)  loss_objectness: 0.0874 (0.1729)  loss_rpn_box_reg: 0.0201 (0.0669)\n",
      "Fine Epoch: [0]  [200/971]  lr: 0.001040  loss: 0.1922 (0.3231)  loss_classifier: 0.0504 (0.0799)  loss_box_reg: 0.0370 (0.0198)  loss_objectness: 0.0714 (0.1624)  loss_rpn_box_reg: 0.0205 (0.0610)\n",
      "Coarse Epoch: [0]  [200/971]  lr: 0.001040  loss: 0.1801 (0.2898)  loss_classifier: 0.0579 (0.0613)  loss_box_reg: 0.0400 (0.0207)  loss_objectness: 0.0602 (0.1499)  loss_rpn_box_reg: 0.0235 (0.0579)\n",
      "Fine Epoch: [0]  [250/971]  lr: 0.001298  loss: 0.1814 (0.3045)  loss_classifier: 0.0630 (0.0781)  loss_box_reg: 0.0369 (0.0241)  loss_objectness: 0.0529 (0.1464)  loss_rpn_box_reg: 0.0149 (0.0559)\n",
      "Coarse Epoch: [0]  [250/971]  lr: 0.001298  loss: 0.1764 (0.2764)  loss_classifier: 0.0612 (0.0631)  loss_box_reg: 0.0345 (0.0245)  loss_objectness: 0.0439 (0.1351)  loss_rpn_box_reg: 0.0166 (0.0537)\n",
      "Fine Epoch: [0]  [300/971]  lr: 0.001555  loss: 0.1633 (0.2923)  loss_classifier: 0.0668 (0.0778)  loss_box_reg: 0.0390 (0.0273)  loss_objectness: 0.0385 (0.1339)  loss_rpn_box_reg: 0.0169 (0.0534)\n",
      "Coarse Epoch: [0]  [300/971]  lr: 0.001555  loss: 0.1381 (0.2647)  loss_classifier: 0.0549 (0.0635)  loss_box_reg: 0.0340 (0.0268)  loss_objectness: 0.0281 (0.1233)  loss_rpn_box_reg: 0.0218 (0.0511)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 333\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 334\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 335\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 336\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 337\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 338\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 339\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 340\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 341\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 342\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 343\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 344\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 345\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 346\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 347\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 348\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 349\n",
      "RL nb: \n",
      " 971\n",
      "Fine Epoch: [0]  [350/971]  lr: 0.001812  loss: 0.2280 (0.2860)  loss_classifier: 0.0740 (0.0777)  loss_box_reg: 0.0332 (0.0294)  loss_objectness: 0.0729 (0.1264)  loss_rpn_box_reg: 0.0371 (0.0525)\n",
      "Coarse Epoch: [0]  [350/971]  lr: 0.001812  loss: 0.2088 (0.2615)  loss_classifier: 0.0598 (0.0651)  loss_box_reg: 0.0343 (0.0291)  loss_objectness: 0.0625 (0.1169)  loss_rpn_box_reg: 0.0306 (0.0504)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 350\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 351\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 352\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 353\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 354\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 355\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 356\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 357\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 358\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 359\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 360\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 361\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 362\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 363\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 364\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 365\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 366\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 367\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 368\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 369\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 370\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 371\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 372\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 373\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 374\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 375\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 376\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 377\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 378\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 379\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 380\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 381\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 382\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 383\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 384\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 385\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 386\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 387\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 388\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 389\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 390\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 391\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 392\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 393\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 394\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 395\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 396\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 397\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 398\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 399\n",
      "RL nb: \n",
      " 971\n",
      "Fine Epoch: [0]  [400/971]  lr: 0.002070  loss: 0.1248 (0.2750)  loss_classifier: 0.0467 (0.0765)  loss_box_reg: 0.0304 (0.0310)  loss_objectness: 0.0261 (0.1174)  loss_rpn_box_reg: 0.0123 (0.0502)\n",
      "Coarse Epoch: [0]  [400/971]  lr: 0.002070  loss: 0.1199 (0.2545)  loss_classifier: 0.0487 (0.0655)  loss_box_reg: 0.0332 (0.0311)  loss_objectness: 0.0208 (0.1094)  loss_rpn_box_reg: 0.0150 (0.0485)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 400\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 401\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 402\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 403\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 404\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 405\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 406\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 407\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 408\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 409\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 410\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 411\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 412\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 413\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL batch_iter: \n",
      " 414\n",
      "RL nb: \n",
      " 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL training is ongoing! buffer size is more than 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:01<00:01,  1.88it/s]"
     ]
    }
   ],
   "source": [
    "for e in range(epochs):\n",
    "    # label이 없더라도 loader에 image 생성\n",
    "    train_imgs = load_filenames(split_train_path, split, bs).files_array()\n",
    "    fine_train_dataset = load_dataset(train_imgs, fine_tr, bs)\n",
    "    coarse_train_dataset = load_dataset(train_imgs, fine_tr, bs)\n",
    "\n",
    "    fine_train_loader = load_dataloader(bs, fine_train_dataset)\n",
    "    coarse_train_loader = load_dataloader(bs, coarse_train_dataset)\n",
    "\n",
    "    fine_train_nb = len(fine_train_loader)\n",
    "    coarse_train_nb = len(coarse_train_loader)\n",
    "    assert fine_train_nb == coarse_train_nb, 'fine & coarse train batch number is not matched'\n",
    "    nb = fine_train_nb\n",
    "    \n",
    "    # Logger\n",
    "    fine_metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
    "    fine_metric_logger.add_meter('lr', utils.SmoothedValue(window_size=1, fmt='{value:.6f}'))\n",
    "    coarse_metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
    "    coarse_metric_logger.add_meter('lr', utils.SmoothedValue(window_size=1, fmt='{value:.6f}'))   \n",
    "    fine_header = 'Fine Epoch: [{}]'.format(e)\n",
    "    coarse_header = 'Coarse Epoch: [{}]'.format(e)\n",
    "    \n",
    "#     # warmup\n",
    "    fine_lr_scheduler = None\n",
    "    corase_lr_scheduler = None\n",
    "    if e == 0:\n",
    "        warmup_factor = 1. / 1000\n",
    "        warmup_iters = min(1000, fine_train_nb-1)\n",
    "        fine_lr_scheduler = utils.warmup_lr_scheduler(fine_optim, warmup_iters, warmup_factor)\n",
    "        coarse_lr_scheduler = utils.warmup_lr_scheduler(coarse_optim, warmup_iters, warmup_factor)\n",
    "    \n",
    "    for i, (fine_train, coarse_train) in enumerate(zip(fine_train_loader, coarse_train_loader)):\n",
    "        # train\n",
    "        fine_model.train()\n",
    "        coarse_model.train()\n",
    "        #### fine train ###\n",
    "        # Label mathching\n",
    "        fine_imgs, fine_labels = label_matching(fine_train, device)\n",
    "        fine_imgs = fine_imgs.to(device) / 255.\n",
    "        \n",
    "        ## train: img normalization --> not, zerodivision err\n",
    "        fine_loss_dict = fine_model(fine_imgs, copy.deepcopy(fine_labels))       \n",
    "        fine_losses = sum(loss for loss in fine_loss_dict.values())        \n",
    "        fine_loss_dict_reduced = reduce_dict(fine_loss_dict)\n",
    "        fine_loss_reduced = sum(loss for loss in fine_loss_dict_reduced.values())\n",
    "        fine_loss_val = fine_loss_reduced.item()\n",
    "\n",
    "        # optimizer\n",
    "        fine_optim.zero_grad()\n",
    "        fine_losses.backward()\n",
    "        fine_optim.step()\n",
    "        \n",
    "        if fine_lr_scheduler is not None:\n",
    "            fine_lr_scheduler.step()\n",
    "        \n",
    "        fine_metric_logger.update(loss=fine_loss_reduced, **fine_loss_dict_reduced)\n",
    "        fine_metric_logger.update(lr=fine_optim.param_groups[0][\"lr\"])\n",
    "        \n",
    "        if i % opt.print_freq ==0:\n",
    "            space_fmt = ':' + str(len(str(fine_train_nb))) + 'd'\n",
    "            log_msg = fine_metric_logger.delimiter.join([fine_header, '[{0' + space_fmt + '}/{1}]', '{meters}'])\n",
    "            print(log_msg.format(i, fine_train_nb, meters=str(fine_metric_logger)))\n",
    "        \n",
    "        ### coarse train ###\n",
    "        # Label mathching\n",
    "        coarse_imgs, coarse_labels = label_matching(coarse_train, device)\n",
    "        coarse_imgs = coarse_imgs.to(device) / 255.\n",
    "        \n",
    "        \n",
    "        ## train: img normalization --> not, zerodivision err\n",
    "        coarse_loss_dict = coarse_model(coarse_imgs, copy.deepcopy(coarse_labels))\n",
    "        coarse_losses = sum(loss for loss in coarse_loss_dict.values())\n",
    "        \n",
    "        # utils\n",
    "        coarse_loss_dict_reduced = reduce_dict(coarse_loss_dict)\n",
    "        coarse_loss_reduced = sum(loss for loss in coarse_loss_dict_reduced.values())\n",
    "        coarse_loss_val = coarse_loss_reduced.item()\n",
    "        \n",
    "        # optimizer\n",
    "        coarse_optim.zero_grad()\n",
    "        coarse_losses.backward()\n",
    "        coarse_optim.step()\n",
    "        \n",
    "        if coarse_lr_scheduler is not None:\n",
    "            coarse_lr_scheduler.step()\n",
    "        \n",
    "        coarse_metric_logger.update(loss=coarse_loss_reduced, **coarse_loss_dict_reduced)\n",
    "        coarse_metric_logger.update(lr=fine_optim.param_groups[0][\"lr\"]) \n",
    "        \n",
    "        if i % opt.print_freq ==0:\n",
    "            space_fmt = ':' + str(len(str(fine_train_nb))) + 'd'\n",
    "            log_msg = coarse_metric_logger.delimiter.join([coarse_header, '[{0' + space_fmt + '}/{1}]', '{meters}'])\n",
    "            print(log_msg.format(i, fine_train_nb, meters=str(coarse_metric_logger)))\n",
    "            \n",
    "        ## train eval        \n",
    "        # result = (source_path, paths[si], mp, mr, map50, nl, stats)\n",
    "        # file_name, od_file_dir, mp=0(skip), ma=0(skip), map50(will be soon), objnum, stat\n",
    "        # stat = 4\n",
    "        \n",
    "        # make_results(model, dataset, device)\n",
    "        fine_results = make_results(fine_model, fine_train, device)\n",
    "        coarse_results = make_results(coarse_model, coarse_train, device)\n",
    "            \n",
    "        # conf_thresh=0.001 / iou_thres=0.6\n",
    "        rl_agent.train(e, i, nb, fine_results, coarse_results, original_data_path=original_img_path_train)\n",
    "\n",
    "    ## Validation\n",
    "    if e % 1 == 0:\n",
    "        fine_dataset, coarse_dataset, policies = rl_agent.eval(split_val_path, original_img_path_val)\n",
    "        print(len(fine_dataset.tolist()))\n",
    "        print(len(coarse_dataset.tolist()))\n",
    "        fine_results, coarse_results = [], []\n",
    "\n",
    "        if len(fine_dataset.tolist()) > 0:\n",
    "            fine_val_dataset = load_dataset(fine_dataset, fine_tr, bs)\n",
    "            fine_val_loader = load_dataloader(bs, fine_val_dataset)\n",
    "            fine_nb = len(fine_val_loader)\n",
    "            for i, fine_val in tqdm.tqdm(enumerate(fine_val_loader), total=fine_nb):\n",
    "                fine_results += make_results(fine_model, fine_val, device)\n",
    "\n",
    "        if len(coarse_dataset.tolist()) > 0:\n",
    "            coarse_val_dataset = load_dataset(coarse_dataset, fine_tr, bs)\n",
    "            coarse_val_loader = load_dataloader(bs, coarse_val_dataset)\n",
    "            coarse_nb = len(coarse_train_loader)\n",
    "            for i, coarse_val in tqdm.tqdm(enumerate(coarse_val_loader), total=coarse_nb):\n",
    "                coarse_results += make_results(coarse_model, coarse_val, device)\n",
    "\n",
    "        map50 = compute_map(fine_results, coarse_results)\n",
    "        print('Validation MAP: \\n', map50)\n",
    "        \n",
    "    # save\n",
    "    if e % opt.save_freq == 0:\n",
    "        torch.save(fine_model, 'fine_model')\n",
    "        torch.save(coarse_model, 'coarse_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "fine_dataset, coarse_dataset, policies = rl_agent.eval(split_test_path, original_img_path_test)\n",
    "fine_results, coarse_results = [], []\n",
    "\n",
    "if len(fine_dataset.tolist()) > 0:\n",
    "    fine_test_dataset = load_dataset(fine_dataset, fine_tr, bs)\n",
    "    fine_test_loader = load_dataloader(bs, fine_test_dataset)\n",
    "    fine_nb = len(fine_test_loader)\n",
    "    for i, fine_test in tqdm.tqdm(enumerate(fine_test_loader), total=fine_nb):\n",
    "        fine_results += make_results(fine_model, fine_test, device)\n",
    "\n",
    "if len(coarse_dataset.tolist()) > 0:\n",
    "    coarse_test_dataset = load_dataset(coarse_dataset, fine_tr, bs)\n",
    "    coarse_test_loader = load_dataloader(bs, coarse_test_dataset)\n",
    "    coarse_nb = len(coarse_test_loader)\n",
    "    for i, coarse_test in tqdm.tqdm(enumerate(coarse_test_loader), total=coarse_nb):\n",
    "        coarse_results += make_results(coarse_model, coarse_test, device)\n",
    "\n",
    "map50 = compute_map(fine_results, coarse_results)\n",
    "print('MAP: \\n', map50)\n",
    "\n",
    "with open('test_result.txt', 'a') as f:\n",
    "    f.write(str(map50))\n",
    "\n",
    "with open('test_policies.txt', 'a') as f:\n",
    "    f.write(str(policies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.non_max_suppression(torch.tensor(inf_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = fine_imgs[7].cpu().numpy().swapaxes(0,1).swapaxes(1,2)\n",
    "box = tuple(fine_labels[7]['boxes'].cpu().numpy()[0])\n",
    "# box = tuple(fine_train[1][1][2:].numpy()*480)\n",
    "res = cv2.rectangle(img, (box[0],box[1]), (box[2],box[3]), (0,0,255), 10)\n",
    "arr = cv2.UMat.get(res)\n",
    "plt.imshow(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(fine_imgs[0].cpu().numpy().swapaxes(0,1).swapaxes(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
